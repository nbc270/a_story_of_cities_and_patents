{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk import Tree\n",
    "import itertools\n",
    "import ast\n",
    "from ast import literal_eval\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))\n",
    "import re\n",
    "# %python -m spacy download en  //for installing the english dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/projects/cps2019_funding/shared/Text_Data/New'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pd.read_csv(\"/projects/cps2019_funding/shared/Patents_Data/cityAnalysis/cleaned_patent_years/patents2008_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get subject of each sentence per abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subset of 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam = pat.sample(frac= .001, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert float to str\n",
    "patSam['patent_abstract'] = patSam[['patent_abstract']].replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>IPCs</th>\n",
       "      <th>applications</th>\n",
       "      <th>assignees</th>\n",
       "      <th>cited_patents</th>\n",
       "      <th>cpcs</th>\n",
       "      <th>inventors</th>\n",
       "      <th>nbers</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_id</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>uspcs</th>\n",
       "      <th>wipos</th>\n",
       "      <th>assignee_city</th>\n",
       "      <th>field</th>\n",
       "      <th>sector</th>\n",
       "      <th>ipc_section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91332</th>\n",
       "      <td>91332</td>\n",
       "      <td>2207</td>\n",
       "      <td>[{u'ipc_section': u'H', u'ipc_subclass': u'B',...</td>\n",
       "      <td>[{u'app_type': u'12', u'app_id': u'12/244060'}]</td>\n",
       "      <td>[{u'assignee_key_id': u'271691', u'assignee_ci...</td>\n",
       "      <td>[{u'cited_patent_category': u'cited by other'}...</td>\n",
       "      <td>[{u'cpc_subgroup_title': u'Satellite radio bea...</td>\n",
       "      <td>[{u'inventor_key_id': u'63202', u'inventor_cit...</td>\n",
       "      <td>[{u'nber_category_title': u'Cmp&amp;Cmm', u'nber_s...</td>\n",
       "      <td>An electronic circuit includes a receiver circ...</td>\n",
       "      <td>8331898</td>\n",
       "      <td>utility</td>\n",
       "      <td>[{u'uspc_mainclass_title': u'Telecommunication...</td>\n",
       "      <td>[{u'wipo_field_title': u'Telecommunications', ...</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Electrical engineering</td>\n",
       "      <td>Electrical engineering</td>\n",
       "      <td>[u'H']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19778</th>\n",
       "      <td>19778</td>\n",
       "      <td>9778</td>\n",
       "      <td>[{u'ipc_section': u'G', u'ipc_subclass': u'Q',...</td>\n",
       "      <td>[{u'app_type': u'12', u'app_id': u'12/080976'}]</td>\n",
       "      <td>[{u'assignee_key_id': u'248593', u'assignee_ci...</td>\n",
       "      <td>[{u'cited_patent_category': u'cited by examine...</td>\n",
       "      <td>[{u'cpc_subgroup_title': u'Finance; Insurance;...</td>\n",
       "      <td>[{u'inventor_key_id': u'2680096', u'inventor_c...</td>\n",
       "      <td>[{u'nber_category_title': u'Cmp&amp;Cmm', u'nber_s...</td>\n",
       "      <td>Disclosed is a novel life insurance product th...</td>\n",
       "      <td>8180656</td>\n",
       "      <td>utility</td>\n",
       "      <td>[{u'uspc_mainclass_title': u'Data processing: ...</td>\n",
       "      <td>[{u'wipo_field_title': u'IT methods for manage...</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>Electrical engineering</td>\n",
       "      <td>Electrical engineering</td>\n",
       "      <td>[u'G']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>5719</td>\n",
       "      <td>5719</td>\n",
       "      <td>[{u'ipc_section': u'H', u'ipc_subclass': u'G',...</td>\n",
       "      <td>[{u'app_type': u'12', u'app_id': u'12/106984'}]</td>\n",
       "      <td>[{u'assignee_key_id': u'66842', u'assignee_cit...</td>\n",
       "      <td>[{u'cited_patent_category': u'cited by other'}...</td>\n",
       "      <td>[{u'cpc_subgroup_title': u'Coupling parts supp...</td>\n",
       "      <td>[{u'inventor_key_id': u'1245151', u'inventor_c...</td>\n",
       "      <td>[{u'nber_category_title': u'Elec', u'nber_subc...</td>\n",
       "      <td>A wiring module that can be installed in an el...</td>\n",
       "      <td>7762838</td>\n",
       "      <td>utility</td>\n",
       "      <td>[{u'uspc_mainclass_title': u'Electricity:  con...</td>\n",
       "      <td>[{u'wipo_field_title': u'Electrical machinery,...</td>\n",
       "      <td>Solana Beach</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[u'H']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67276</th>\n",
       "      <td>67276</td>\n",
       "      <td>3340</td>\n",
       "      <td>[{u'ipc_section': None, u'ipc_subclass': None,...</td>\n",
       "      <td>[{u'app_type': u'29', u'app_id': u'29/308481'}]</td>\n",
       "      <td>[{u'assignee_key_id': u'143968', u'assignee_ci...</td>\n",
       "      <td>[{u'cited_patent_category': u'cited by examine...</td>\n",
       "      <td>[{u'cpc_subgroup_title': None, u'cpc_category'...</td>\n",
       "      <td>[{u'inventor_key_id': u'3634633', u'inventor_c...</td>\n",
       "      <td>[{u'nber_category_title': None, u'nber_subcate...</td>\n",
       "      <td></td>\n",
       "      <td>D594674</td>\n",
       "      <td>design</td>\n",
       "      <td>[{u'uspc_mainclass_title': u'Furnishings', u'u...</td>\n",
       "      <td>[{u'wipo_field_title': None, u'wipo_sector_tit...</td>\n",
       "      <td>New Castle</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13915</th>\n",
       "      <td>13915</td>\n",
       "      <td>3915</td>\n",
       "      <td>[{u'ipc_section': u'H', u'ipc_subclass': u'L',...</td>\n",
       "      <td>[{u'app_type': u'12', u'app_id': u'12/037845'}]</td>\n",
       "      <td>[{u'assignee_key_id': u'86418', u'assignee_cit...</td>\n",
       "      <td>[{u'cited_patent_category': u'cited by other'}...</td>\n",
       "      <td>[{u'cpc_subgroup_title': u'Network architectur...</td>\n",
       "      <td>[{u'inventor_key_id': u'123027', u'inventor_ci...</td>\n",
       "      <td>[{u'nber_category_title': u'Cmp&amp;Cmm', u'nber_s...</td>\n",
       "      <td>A trusted communication system and methods of ...</td>\n",
       "      <td>7996890</td>\n",
       "      <td>utility</td>\n",
       "      <td>[{u'uspc_mainclass_title': u'Information secur...</td>\n",
       "      <td>[{u'wipo_field_title': u'Digital communication...</td>\n",
       "      <td>El Segundo</td>\n",
       "      <td>Electrical engineering</td>\n",
       "      <td>Electrical engineering</td>\n",
       "      <td>[u'H']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  \\\n",
       "91332       91332          2207   \n",
       "19778       19778          9778   \n",
       "5719         5719          5719   \n",
       "67276       67276          3340   \n",
       "13915       13915          3915   \n",
       "\n",
       "                                                    IPCs  \\\n",
       "91332  [{u'ipc_section': u'H', u'ipc_subclass': u'B',...   \n",
       "19778  [{u'ipc_section': u'G', u'ipc_subclass': u'Q',...   \n",
       "5719   [{u'ipc_section': u'H', u'ipc_subclass': u'G',...   \n",
       "67276  [{u'ipc_section': None, u'ipc_subclass': None,...   \n",
       "13915  [{u'ipc_section': u'H', u'ipc_subclass': u'L',...   \n",
       "\n",
       "                                          applications  \\\n",
       "91332  [{u'app_type': u'12', u'app_id': u'12/244060'}]   \n",
       "19778  [{u'app_type': u'12', u'app_id': u'12/080976'}]   \n",
       "5719   [{u'app_type': u'12', u'app_id': u'12/106984'}]   \n",
       "67276  [{u'app_type': u'29', u'app_id': u'29/308481'}]   \n",
       "13915  [{u'app_type': u'12', u'app_id': u'12/037845'}]   \n",
       "\n",
       "                                               assignees  \\\n",
       "91332  [{u'assignee_key_id': u'271691', u'assignee_ci...   \n",
       "19778  [{u'assignee_key_id': u'248593', u'assignee_ci...   \n",
       "5719   [{u'assignee_key_id': u'66842', u'assignee_cit...   \n",
       "67276  [{u'assignee_key_id': u'143968', u'assignee_ci...   \n",
       "13915  [{u'assignee_key_id': u'86418', u'assignee_cit...   \n",
       "\n",
       "                                           cited_patents  \\\n",
       "91332  [{u'cited_patent_category': u'cited by other'}...   \n",
       "19778  [{u'cited_patent_category': u'cited by examine...   \n",
       "5719   [{u'cited_patent_category': u'cited by other'}...   \n",
       "67276  [{u'cited_patent_category': u'cited by examine...   \n",
       "13915  [{u'cited_patent_category': u'cited by other'}...   \n",
       "\n",
       "                                                    cpcs  \\\n",
       "91332  [{u'cpc_subgroup_title': u'Satellite radio bea...   \n",
       "19778  [{u'cpc_subgroup_title': u'Finance; Insurance;...   \n",
       "5719   [{u'cpc_subgroup_title': u'Coupling parts supp...   \n",
       "67276  [{u'cpc_subgroup_title': None, u'cpc_category'...   \n",
       "13915  [{u'cpc_subgroup_title': u'Network architectur...   \n",
       "\n",
       "                                               inventors  \\\n",
       "91332  [{u'inventor_key_id': u'63202', u'inventor_cit...   \n",
       "19778  [{u'inventor_key_id': u'2680096', u'inventor_c...   \n",
       "5719   [{u'inventor_key_id': u'1245151', u'inventor_c...   \n",
       "67276  [{u'inventor_key_id': u'3634633', u'inventor_c...   \n",
       "13915  [{u'inventor_key_id': u'123027', u'inventor_ci...   \n",
       "\n",
       "                                                   nbers  \\\n",
       "91332  [{u'nber_category_title': u'Cmp&Cmm', u'nber_s...   \n",
       "19778  [{u'nber_category_title': u'Cmp&Cmm', u'nber_s...   \n",
       "5719   [{u'nber_category_title': u'Elec', u'nber_subc...   \n",
       "67276  [{u'nber_category_title': None, u'nber_subcate...   \n",
       "13915  [{u'nber_category_title': u'Cmp&Cmm', u'nber_s...   \n",
       "\n",
       "                                         patent_abstract patent_id  \\\n",
       "91332  An electronic circuit includes a receiver circ...   8331898   \n",
       "19778  Disclosed is a novel life insurance product th...   8180656   \n",
       "5719   A wiring module that can be installed in an el...   7762838   \n",
       "67276                                                      D594674   \n",
       "13915  A trusted communication system and methods of ...   7996890   \n",
       "\n",
       "      patent_type                                              uspcs  \\\n",
       "91332     utility  [{u'uspc_mainclass_title': u'Telecommunication...   \n",
       "19778     utility  [{u'uspc_mainclass_title': u'Data processing: ...   \n",
       "5719      utility  [{u'uspc_mainclass_title': u'Electricity:  con...   \n",
       "67276      design  [{u'uspc_mainclass_title': u'Furnishings', u'u...   \n",
       "13915     utility  [{u'uspc_mainclass_title': u'Information secur...   \n",
       "\n",
       "                                                   wipos assignee_city  \\\n",
       "91332  [{u'wipo_field_title': u'Telecommunications', ...        Dallas   \n",
       "19778  [{u'wipo_field_title': u'IT methods for manage...      Hartford   \n",
       "5719   [{u'wipo_field_title': u'Electrical machinery,...  Solana Beach   \n",
       "67276  [{u'wipo_field_title': None, u'wipo_sector_tit...    New Castle   \n",
       "13915  [{u'wipo_field_title': u'Digital communication...    El Segundo   \n",
       "\n",
       "                        field                  sector ipc_section  \n",
       "91332  Electrical engineering  Electrical engineering      [u'H']  \n",
       "19778  Electrical engineering  Electrical engineering      [u'G']  \n",
       "5719                     None                    None      [u'H']  \n",
       "67276                    None                    None      [None]  \n",
       "13915  Electrical engineering  Electrical engineering      [u'H']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patSam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get noun chunk from each abstract\n",
    "\n",
    "Notice the example below: if we only obtain subject...the returned words are not descriptive of the idea itself.\n",
    "\n",
    "## Ex: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Disclosed is a novel life insurance product that provides an improved return to a purchaser. The life insurance product contains a benefit payment, and has a fixed benefit amount and a variable benefit amount. A policy protection benefit prevents a purchaser's life insurance product from lapsing, and a minimum death benefit ensures that the purchaser receives the greater of the face value of the product and a predetermined percentage of the account value.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patSam['patent_abstract'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[that, product, benefit, purchaser]\n"
     ]
    }
   ],
   "source": [
    "doc = en_nlp(unicode(patSam['patent_abstract'].values[1], \"utf-8\"))\n",
    "\n",
    "sub_toks = [tok for tok in doc if (tok.dep_ == \"nsubj\") ]\n",
    "\n",
    "print(sub_toks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This example had nothing about insurance or policy or death"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This example has nothing about sensor or vehicle\n",
    "\n",
    "Now, let us try with noun chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a novel life insurance product\n",
      "an improved return\n",
      "a purchaser\n",
      "The life insurance product\n",
      "a benefit payment\n",
      "a fixed benefit amount\n",
      "a variable benefit amount\n",
      "A policy protection benefit\n",
      "a purchaser's life insurance product\n",
      "the purchaser\n",
      "the face value\n",
      "the product\n",
      "a predetermined percentage\n",
      "the account value\n"
     ]
    }
   ],
   "source": [
    "for np in doc.noun_chunks:\n",
    "    print np.text #, np.root.dep_, np.root.head.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam['patent_abstract'].values[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = en_nlp(unicode(patSam['patent_abstract'].values[5], \"utf-8\"))\n",
    "\n",
    "sub_toks = [tok for tok in doc if (tok.dep_ == \"nsubj\") ]\n",
    "\n",
    "print(sub_toks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This example has nothing about sensor or vehicle\n",
    "\n",
    "Now, let us try with noun chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for np in doc.noun_chunks:\n",
    "    print np.text #, np.root.dep_, np.root.head.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I will get the words that show up most often from all the noun chunks, and exclude the stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = patSam['patent_abstract'].apply(lambda x: list(en_nlp(unicode(x,\"utf-8\")).noun_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prod.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(prod.values[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"[^\\w]\", \" \",  str(prod.values[0][1])).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for i in range(len(prod.values[1])):\n",
    "    words = re.sub(\"[^\\w]\", \" \",  str(prod.values[1][i])).split()\n",
    "   # print words\n",
    "    all_words = (all_words + words)\n",
    "    #print(all_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'novel',\n",
       " 'life',\n",
       " 'insurance',\n",
       " 'product',\n",
       " 'an',\n",
       " 'improved',\n",
       " 'return',\n",
       " 'a',\n",
       " 'purchaser',\n",
       " 'The',\n",
       " 'life',\n",
       " 'insurance',\n",
       " 'product',\n",
       " 'a',\n",
       " 'benefit',\n",
       " 'payment',\n",
       " 'a',\n",
       " 'fixed',\n",
       " 'benefit',\n",
       " 'amount',\n",
       " 'a',\n",
       " 'variable',\n",
       " 'benefit',\n",
       " 'amount',\n",
       " 'A',\n",
       " 'policy',\n",
       " 'protection',\n",
       " 'benefit',\n",
       " 'a',\n",
       " 'purchaser',\n",
       " 's',\n",
       " 'life',\n",
       " 'insurance',\n",
       " 'product',\n",
       " 'the',\n",
       " 'purchaser',\n",
       " 'the',\n",
       " 'face',\n",
       " 'value',\n",
       " 'the',\n",
       " 'product',\n",
       " 'a',\n",
       " 'predetermined',\n",
       " 'percentage',\n",
       " 'the',\n",
       " 'account',\n",
       " 'value']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'product',\n",
       " 'benefit',\n",
       " 'the',\n",
       " 'purchaser',\n",
       " 'insurance',\n",
       " 'life',\n",
       " 'amount',\n",
       " 'value',\n",
       " 'an',\n",
       " 'policy',\n",
       " 'percentage',\n",
       " 'A',\n",
       " 'return',\n",
       " 'protection',\n",
       " 'variable',\n",
       " 'The',\n",
       " 'payment',\n",
       " 'account',\n",
       " 'novel',\n",
       " 'improved',\n",
       " 'face',\n",
       " 's',\n",
       " 'predetermined',\n",
       " 'fixed']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter = {}\n",
    "for word in all_words:\n",
    "    if word in word_counter:\n",
    "        word_counter[word] += 1\n",
    "    else:\n",
    "        word_counter[word] = 1\n",
    "\n",
    "popular_words = sorted(word_counter, key = word_counter.get, reverse = True); popular_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product', 'benefit', 'purchaser', 'insurance', 'life']\n"
     ]
    }
   ],
   "source": [
    "filtered_sentence = [w for w in popular_words if not w in stop_words] \n",
    "  \n",
    "filtered_sentence = [] \n",
    "  \n",
    "for w in popular_words: \n",
    "    if w not in stop_words: \n",
    "        filtered_sentence.append(w) \n",
    "   \n",
    "print(filtered_sentence[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function that takes a dataset and threshold for how many top words you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyWord(df, num_words):\n",
    "    prod = df['patent_abstract'].apply(lambda x: list(en_nlp(unicode(x,\"utf-8\")).noun_chunks))\n",
    "    all_words = []\n",
    "    for i in range(len(prod.values[0])):  \n",
    "        words = re.sub(\"[^\\w]\", \" \",  str(prod.values[0][i])).split()\n",
    "       # print words\n",
    "        all_words = (all_words + words)\n",
    "        return all_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An', 'electronic', 'circuit']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyWord(patSam, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lines = ['The query complexity of estimating weighted averages.',\n",
    " 'New bounds for the query complexity of an algorithm that learns',\n",
    " 'DFAs with correction equivalence queries.',\n",
    " 'general procedure to check conjunctive query containment.']\n",
    "\n",
    "joint_words = ' '.join(lines)\n",
    "\n",
    "separated_words = word_tokenize(joint_words)\n",
    "\n",
    "print(separated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for i in range(len(prod.values[0])):\n",
    "    all_words.append(str(prod.values[0][i]).split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(itertools.zip_longest(*[iter(l)] * 2, fillvalue=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(prod.values[2][1]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = {}\n",
    "for word in prod.values[0]:\n",
    "    if word in word_counter:\n",
    "        word_counter[word] += 1\n",
    "    else:\n",
    "        word_counter[word] = 1\n",
    "\n",
    "#popular_words = \n",
    "sorted(word_counter, key = word_counter.get, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam['noun_chunk'] = patSam['patent_abstract'].dropna().apply(lambda x: list(\n",
    "    en_nlp(unicode(x,\"utf-8\")).noun_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = patSam['noun_chunk'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    print(str(test[i]).split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_nsub(df):\n",
    "    df['patent_abstract'].dropna().apply(lambda x: list(\n",
    "    en_nlp(unicode(x,\"utf-8\")).noun_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output city matched with its index number so that we can use the index number to extract rows from dataframe \n",
    "#for different cities\n",
    "def find_cities(df):\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            yield (i, literal_eval(pat04['assignees'][i])[0]['assignee_city'])\n",
    "        except SyntaxError:\n",
    "            yield (i, 'TBD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output a list of tuples with unique cities and corresponding number of patents\n",
    "def count_cities(l):\n",
    "    counts = {}\n",
    "    for tup in l:\n",
    "        counts[tup[1]] = counts.get(tup[1], 0) + 1\n",
    "    return sorted(counts.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = list(find_cities(patSam))\n",
    "cities_counts = count_cities(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(cities[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import nsubj, nsubjpass, dobj, iobj, pobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = en_nlp(u'The cat and the dog sleep in the basket near the door.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_labels = set([nsubj, nsubjpass, dobj, iobj, pobj]) # Probably others too\n",
    "def iter_nps(doc):\n",
    "    for word in doc:\n",
    "        if word.dep_ in np_labels:\n",
    "            yield word.subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_nps(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam['patent_abstract'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode(patSam['patent_abstract'].values[1], \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = en_nlp(unicode(\"Other circuits, devices, systems, \\\n",
    "                     methods of operation and processes of manufacture are also disclosed.\", \"utf-8\"))\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = en_nlp(unicode(patSam['patent_abstract'].values[1], \"utf-8\"))\n",
    "\n",
    "sentence = next(doc.sents) \n",
    "for word in sentence:\n",
    "    print( \"%s:%s\" % (word,word.dep_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that simple taking nsub might not result in the most meaningful part of sentence. As shown in insurance example. However...because we are aggregating this might be a trivial issue in the grand scheme.\n",
    "\n",
    "Lets make a function to store all nsubj for each abstract in dataframe. Then group by...then see what words come to top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam['patent_abstract'].apply(lambda x: list(en_nlp(unicode(x,\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = patSam['patent_abstract'].apply(lambda x: en_nlp(unicode(x,\"utf-8\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsub_list = []\n",
    "for i in range(len(temp)):      \n",
    "    nsub_list.append([tok for tok in temp.values[i] if (tok.dep_ == \"nsubj\") ])\n",
    "\n",
    "    #patSam['nsub'] = [tok for tok in temp.values[i] if (tok.dep_ == \"nsubj\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(nsub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam['nsub'] = pd.DataFrame(np.array(nsub_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsubMaker(df):\n",
    "    temp = df['patent_abstract'].apply(lambda x: en_nlp(unicode(x,\"utf-8\")))\n",
    "    print(temp.values[0])\n",
    "    for i in range(len(temp)):      \n",
    "        print([tok for tok in temp.values[i] if (tok.dep_ == \"nsubj\") ])\n",
    "        \n",
    "        df['nsub'] = [tok for tok in temp.values[i] if (tok.dep_ == \"nsubj\") ]\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam['patent_abstract'].apply(lambda x: en_nlp(unicode(x,\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam[\"nlp\"] = patSam['patent_abstract'].apply(lambda x: en_nlp(unicode(x,\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
