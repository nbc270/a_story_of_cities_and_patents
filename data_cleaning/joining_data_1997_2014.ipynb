{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in empowerment zone data\n",
    "ez = pd.read_csv('Regulation_Data/EZ_EC_RC/EZs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿Round_I (1993-1994)</th>\n",
       "      <th>Round_II (1997-1999)</th>\n",
       "      <th>Round_III (2000)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Fresno, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Jacksonville, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Columbia, SC</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>Sumter, SC</td>\n",
       "      <td>Pulaski County, AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Columbus, OH</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ﻿Round_I (1993-1994) Round_II (1997-1999)    Round_III (2000)\n",
       "0          Atlanta, GA           Boston, MA          Fresno, CA\n",
       "1        Baltimore, MD       Cincinnati, OH    Jacksonville, FL\n",
       "2          Chicago, IL         Columbia, SC   Oklahoma City, OK\n",
       "3          Detroit, MI           Sumter, SC  Pulaski County, AR\n",
       "4         New York, NY         Columbus, OH     San Antonio, TX"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ez.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['﻿Round_I (1993-1994)', 'Round_II (1997-1999)', 'Round_III (2000)'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ez.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a signle array of cities that have been empowerment zones\n",
    "ez_new_df = ez['﻿Round_I (1993-1994)'].append(ez['Round_II (1997-1999)'].append(ez['Round_III (2000)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn array into dataframe\n",
    "ez_fixed = pd.DataFrame(ez_new_df)\n",
    "ez_fixed = ez_fixed.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index\n",
    "ez_fixed.columns = ['new_index','cities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate cities\n",
    "ez_fixed = ez_fixed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#separate city and state to create the unique key in the next cell that is found in the other datasets\n",
    "city_state = ez_fixed['cities'].str.split(',',expand = True)\n",
    "ez_fixed['city']  =  city_state[0]\n",
    "ez_fixed['state']  =  city_state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_index</th>\n",
       "      <th>cities</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>city_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>Atlanta_ GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>MD</td>\n",
       "      <td>Baltimore_ MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago_ IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>MI</td>\n",
       "      <td>Detroit_ MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York_ NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_index         cities       city state     city_state\n",
       "0          0    Atlanta, GA    Atlanta    GA    Atlanta_ GA\n",
       "1          1  Baltimore, MD  Baltimore    MD  Baltimore_ MD\n",
       "2          2    Chicago, IL    Chicago    IL    Chicago_ IL\n",
       "3          3    Detroit, MI    Detroit    MI    Detroit_ MI\n",
       "4          4   New York, NY   New York    NY   New York_ NY"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ez_fixed['city_state'] = ez_fixed['city'] + '_' + ez_fixed['state']\n",
    "ez_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Remove spaces and characters that could potentially be found in the city_state column\n",
    "ez_fixed['city_state'] = ez_fixed['city_state'].str.replace(' ','')\n",
    "ez_fixed['city_state'] = ez_fixed['city_state'].str.replace(',','')\n",
    "ez_fixed['city_state'] = ez_fixed['city_state'].str.replace('.','')\n",
    "ez_fixed['city_state'] = ez_fixed['city_state'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn column into a list\n",
    "empowerment_cities = list(ez_fixed['city_state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#years to loop through\n",
    "years = list(range(2001,2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 19971997\n",
      "1997\n",
      "in 19971998\n",
      "1998\n",
      "in 19971999\n",
      "1999\n",
      "in 19972000\n",
      "2000\n",
      "in 19972001\n",
      "2001\n",
      "in 20022002\n",
      "2002\n",
      "in 20022003\n",
      "2003\n",
      "in 20022004\n",
      "2004\n",
      "in 20022005\n",
      "2005\n",
      "in 20022006\n",
      "2006\n",
      "in 20072007\n",
      "2007\n",
      "in 20072008\n",
      "2008\n",
      "in 20072009\n",
      "2009\n",
      "in 20072010\n",
      "2010\n",
      "in 20072011\n",
      "2011\n",
      "in 20122012\n",
      "2012\n",
      "in 20122013\n",
      "2013\n",
      "in 20122014\n",
      "2014\n"
     ]
    }
   ],
   "source": [
    "final_list = []\n",
    "cities = pd.read_csv('Patents_Data/cities_with_scores.csv')\n",
    "for i in years:\n",
    "    \n",
    "    #patent data\n",
    "    patents = cities.loc[cities['Year']==int(float(i))]\n",
    "    patents['city_state'] = patents['city_state'].str.replace(' ','')\n",
    "    patents['city_state'] = patents['city_state'].str.replace(',','')\n",
    "    patents['city_state'] = patents['city_state'].str.replace('.','')\n",
    "    patents['city_state'] = patents['city_state'].str.lower()\n",
    "    patents['year'] = i\n",
    "    \n",
    "    #sbir data\n",
    "    sbir = pd.read_csv('Regulation_Data/SBIR/clean_SBIR/clean_sbir_'+str(i)+'.csv')\n",
    "    sbir['City_State'] = sbir['City_State'].str.replace(' ','')\n",
    "    sbir['City_State'] = sbir['City_State'].str.replace(',','')\n",
    "    sbir['City_State'] = sbir['City_State'].str.replace('.','')\n",
    "    sbir['City_State'] = sbir['City_State'].str.lower()\n",
    "    \n",
    "    #first join\n",
    "    sbir_cities = patents.merge(sbir, left_on = 'city_state', right_on = 'City_State', how = 'left')\n",
    "    \n",
    "    #econ data\n",
    "    if int(float(i)) < 2002:\n",
    "        print(\"in 1997\" + str(i))\n",
    "        econ = pd.read_csv('econ_data/1997_creative_class.csv')\n",
    "    if (int(float(i)) < 2007) & (int(float(i)) >= 2002):\n",
    "        print(\"in 2002\" + str(i))\n",
    "        econ = pd.read_csv('econ_data/2002_creative_class.csv')\n",
    "    if (int(float(i)) < 2012) & (int(float(i)) >= 2007):\n",
    "        print(\"in 2007\" + str(i))\n",
    "        econ = pd.read_csv('econ_data/2007_creative_class.csv')\n",
    "    if int(float(i)) >= 2012:\n",
    "        print(\"in 2012\" + str(i))\n",
    "        econ = pd.read_csv('econ_data/2012_creative_class.csv')\n",
    "    econ['city_state'] = econ['city_state'].str.replace(' ','')\n",
    "    econ['city_state'] = econ['city_state'].str.replace('.','')\n",
    "    econ['city_state'] = econ['city_state'].str.replace(',','')\n",
    "    econ['city_state'] = econ['city_state'].str.lower()\n",
    "    \n",
    "    #second join\n",
    "    sbir_creative_cities = sbir_cities.merge(econ,left_on = 'city_state', right_on = 'city_state', how = 'left')\n",
    "    \n",
    "    #fill sbir NaN with zero\n",
    "    sbir_creative_cities['Award Mean'] = sbir_creative_cities['Award Mean'].fillna(0)\n",
    "    sbir_creative_cities['Award Sum'] = sbir_creative_cities['Award Sum'].fillna(0)\n",
    "    sbir_creative_cities['Company Count'] = sbir_creative_cities['Company Count'].fillna(0)\n",
    "    \n",
    "    #regulation data\n",
    "    if i < 2001:\n",
    "        sbir_creative_ff_cities = sbir_creative_cities\n",
    "        \n",
    "    if (i >= 2001) & (i<2013):\n",
    "        performance = pd.read_csv('Regulation_Data/Federal_Funding/FF'+str(i)+'_performance.csv')\n",
    "        recipient = pd.read_csv('Regulation_Data/Federal_Funding/FF'+str(i)+'_recipient.csv')\n",
    "    \n",
    "        performance['city_state_abrv'] = performance['primary_place_of_performance_city_name'] + '_' + performance['primary_place_of_performance_state_code']\n",
    "        recipient['city_state_abrv'] = recipient['recipient_city_name'] + '_' + recipient['recipient_state_code']\n",
    "    \n",
    "        performance['city_state_abrv'] = performance['city_state_abrv'].str.replace(' ','')\n",
    "        performance['city_state_abrv'] = performance['city_state_abrv'].str.replace(',','')\n",
    "        performance['city_state_abrv'] = performance['city_state_abrv'].str.replace('.','')\n",
    "        performance['city_state_abrv'] = performance['city_state_abrv'].str.lower()\n",
    "    \n",
    "        recipient['city_state_abrv'] = recipient['city_state_abrv'].str.replace(' ','')\n",
    "        recipient['city_state_abrv'] = recipient['city_state_abrv'].str.replace(',','')\n",
    "        recipient['city_state_abrv'] = recipient['city_state_abrv'].str.replace('.','')\n",
    "        recipient['city_state_abrv'] = recipient['city_state_abrv'].str.lower()\n",
    "    \n",
    "        #third and fourth joins\n",
    "        sbir_creative_performance_cities = sbir_creative_cities.merge(performance,left_on = 'City_State', right_on = 'city_state_abrv', how = 'left')\n",
    "        sbir_creative_ff_cities = sbir_creative_performance_cities.merge(recipient,left_on = 'City_State', right_on = 'city_state_abrv', how = 'left')\n",
    "        sbir_creative_ff_cities['performance_count'] = sbir_creative_ff_cities['performance_count'].fillna(0)\n",
    "        sbir_creative_ff_cities['performance_amount'] = sbir_creative_ff_cities['performance_amount'].fillna(0)\n",
    "        sbir_creative_ff_cities['recipient_count'] = sbir_creative_ff_cities['recipient_count'].fillna(0)\n",
    "        sbir_creative_ff_cities['recipient_amount'] = sbir_creative_ff_cities['recipient_amount'].fillna(0)\n",
    "        sbir_creative_ff_cities =  sbir_creative_ff_cities.drop(['Unnamed: 0_y.1', 'performance_city_state',\n",
    "       'primary_place_of_performance_city_name',\n",
    "       'primary_place_of_performance_state_code', 'city_state_abrv_x',\n",
    "       'Unnamed: 0.1', 'recipient_city_state', 'recipient_city_name', 'recipient_state_code',\n",
    "       'city_state_abrv_y'], axis = 1)\n",
    "        \n",
    "    if i >= 2013:\n",
    "        sbir_creative_ff_cities = sbir_creative_cities\n",
    "        \n",
    "    print(i)\n",
    "    \n",
    "    #case when for empowerment zone\n",
    "    sbir_creative_ff_cities['empowerment_zone'] =  pd.np.where(\n",
    "     sbir_creative_ff_cities['City_State'].isin(empowerment_cities), \n",
    "    '1','0')\n",
    "    \n",
    "    #demographic data\n",
    "    if int(float(i)) < 2000:\n",
    "        demog = pd.read_csv('demog/1990_demographics_finished.csv')\n",
    "    if (int(float(i)) < 2008) & (int(float(i)) >= 2000):\n",
    "        demog = pd.read_csv('demog/2000_demographics_finished.csv')\n",
    "    if int(float(i)) >= 2008:\n",
    "        demog = pd.read_csv('demog/2008_demographics_finished.csv')\n",
    "    \n",
    "    #fifth join\n",
    "    \n",
    "    sbir_creative_ff_demog_cities = sbir_creative_ff_cities.merge(demog,left_on = 'city_state', right_on = 'abrv_city_state', how = 'left')\n",
    "    \n",
    "    #Final Cleaning\n",
    "    sbir_creative_ff_demog_cities = sbir_creative_ff_demog_cities.drop(['Unnamed: 0_x', 'City_x', 'State_x', 'year', 'Unnamed: 0_y', 'City_y','City_State',\n",
    "       'State_y', 'Unnamed: 0','abrv_city_state'], axis=1)\n",
    "    \n",
    "    #Write out the annual data aggregation into a csv\n",
    "    sbir_creative_ff_demog_cities.to_csv('all_collected_data_'+str(i)+'.csv')\n",
    "    \n",
    "    #Append to the list to create a list of dataframes\n",
    "    final_list.append(sbir_creative_ff_demog_cities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
